%tikzstyle
\tikzstyle{decision} = [diamond, draw, fill=blue!20, 
text width=6em, text badly centered, node distance=3cm, inner sep=0pt]
\tikzstyle{block} = [rectangle, draw, fill=blue!20, 
text width=6em, text centered, rounded corners, minimum height=2em]
\tikzstyle{block2} = [rectangle, draw, fill=yellow!20, 
text width=9em, text centered, rounded corners, minimum height=4em]
\tikzstyle{line} = [draw, -latex']
\tikzstyle{cloud} = [draw, ellipse,fill=red!20, node distance=3cm,
minimum height=4em]

In our project we used the open source computer vision library(Opencv) to perform 3D Reconstruction. We implemented both calibrated and Uncalibrated stereo reconstruction techniques using opencv. Opencv uses a pinhole camera model[ref] which works by projecting 3D points onto the image plane using a perspective transformation.

\paragraph{Callibrated}

In calibrated reconstruction the parameters were calculated form the .xml files provided with the images. We used the calculation method followed by \cite{CHAVOREcalculation}, which was implemented as a pyhton script by \cite{CHAVOREcalculation}. For the Callibrated reconstruction we followed the \ref{pipe:calibratedOpencv} pipeline in opencv.


\begin{figure}[H]
	\centering
	\begin{tikzpicture}[node distance = 2cm, auto]
		\node [block] (init) {Input stereo Images};
		\node [block, right of = init, node distance = 3.5cm] (rectify) {Stereo Rectification};
		\node [block, right of = rectify, node distance = 3.5cm] (undistort) {Undistortion Map};
		\node [block, right of = undistort, node distance = 3.5cm] (matching) {Stereo Matching};
		\node [block, right of = matching, node distance =3.5cm] (disp) {Disparity calculation};
		\node [block, above of = disp, node distance = 2cm] (cloud) {Poin Cloud};
		\node [block, below of = disp, node distance = 2cm] (depth) {Depth Map};
		\path [line] (init) -- (rectify);
		\path [line] (rectify) -- (undistort);
		\path [line] (undistort) -- (matching);
		\path [line] (matching) -- (disp);
		\path [line] (disp) -- (cloud);
		\path [line] (disp) -- (depth);
	\end{tikzpicture}
	\label{pipe:calibratedOpencv}
	\caption{Opencv Callibrated pipeline}
\end{figure}

The camera parameters are then used to form the camera matrix, the distortion coefficients and extrinsic matrices. To perform rectification we use \emph{cv2.stereoRectify} function in Opencv which takes thes matrices as inputs and gives the rectified rotation for the left and the right image planes, the left and the right projection equation and the reprojection matrix $Q$. The rectified parameters are then used to create a stereo map for both the images with \emph{cv2.initUndistortRectifyMap} function where we get a Undistortion map for the images. These maps are then given as inputs to \emph{cv2.remap} function where we get the undistorted images as the output.

\begin{lstlisting}[language=python, caption=Rectification and Undistortion]

#Rectification
rectL, rectR, projMatrixL, projMatrixR, QR= cv.stereoRectify(
params.cameraMatrixL, params.distL,params.cameraMatrixR,
params.distR, shapeR, params.extrinscis['R'], params.extrinscis['T'])
	
#Undistortion
stereoMapL = cv.initUndistortRectifyMap(params.cameraMatrixL,
params.distL, rectL, projMatrixL, shapeL, cv.CV_16SC2)
stereoMapR = cv.initUndistortRectifyMap(params.cameraMatrixR,
params.distR, rectR, projMatrixR, shapeR, cv.CV_16SC2)

imgL = cv.remap(self.imageL, stereoMapL[0], stereoMapL[1],
cv.INTER_LANCZOS4, cv.BORDER_CONSTANT, 0)
imgR = cv.remap(self.imageR, stereoMapR[0], stereoMapR[1],
cv.INTER_LANCZOS4, cv.BORDER_CONSTANT, 0)

\end{lstlisting}

The next step involves stereo matching where we implement block matching between the stereo pairs. We first create a block matching object with specific parameters form trail and error. The object is then used to cmpute the disparity map using the \emph{compute} function with the object. To get the 3D points form the disparity map we use the \emph{cv.reprojectImageTo3D} function which takes the disparity map and the reprojection matrix as input to give the 3D points. These points then can be saved as .ply file for viewing.

\begin{lstlisting}[language=python, caption=Disparity Map and Reprojection]
# Create Block matching object. 
stereo = cv.StereoSGBM_create(minDisparity= min_disp,
	numDisparities = num_disp,
	blockSize = block_size,
	uniquenessRatio = 5,
	speckleWindowSize = 5,
	speckleRange = 2,
	disp12MaxDiff = 2,
	P1 = 8 * 3 * block_size**2,
	P2 = 32 * 3 * block_size**2)

#Create Disparity Map
disparity_map = stereo.compute(grayL, grayR)

#Get 3D points
points_3D = cv.reprojectImageTo3D(disparity_map, Q, handleMissingValues=False)

\end{lstlisting}

\paragraph{Uncalibrated}

Uncalibrated reconstruction in Opencv tries to estimate the parameters by using feature matching techniques. It follows the \ref{pipe:uncalibratedOpencv} pipeline where we first use SIFT to detect the keypoints from the stereo images and extract the matching descriptiors using enchanced nearest neighbour method. We then used the lowes test to filter the match with a specific threshold.

\begin{figure}[H]
	\centering
	\begin{tikzpicture}[node distance = 2cm, auto]
		\node [block] (init) {Input stereo Images};
		\node [block, right of = init, node distance = 3.5cm] (keypoints) {Detect Kepoints};
		\node [block, right of = keypoints, node distance = 3.5cm] (match) {Match Descriptors};
		\node [block, right of = match, node distance =3.5cm] (rect) {Rectification};
		\node [block, below of = rect, node distance = 2cm] (disparity) {Disparity};
		\node [block, left of = disparity, node distance = 3.5cm] (3dpoints) {Point Cloud};
		\path [line] (init) -- (keypoints);
		\path [line] (keypoints) -- (match);
		\path [line] (match) -- (rect);
		\path [line] (rect) -- (disparity);
		\path [line] (disparity) -- (3dpoints);
	\end{tikzpicture}
	\label{pipe:uncalibratedOpencv}
	\caption{Opencv UnCallibrated pipeline}
\end{figure}

\begin{lstlisting}[language=python, caption=Feature matching]
sift = cv.SIFT_create()
key1, desc1 = sift.detectAndCompute(image_left, None)
key2, desc2 = sift.detectAndCompute(image_right, None)

#FLANN Enhanced Nearest Neighbour Method
FLANN_INDEX_KDTREE = 1
index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)
search_params = dict(checks=50)
flann = cv.FlannBasedMatcher(index_params,search_params)
Flann_matches = flann.knnMatch(desc1,desc2,k=2)

\end{lstlisting}

The \emph{cv2.stereoRectifyUncalibrated} function is used to get the homography matrices for the images, which is used with \emph{cv2.warpPerspective} to get a rectified image. The disparity for the rectified image is calculated with block matching. We create a reprojection matrix form the camera parameters(cx, cy, focal length and base line). The \emph{cv2.reprojectImageTo3D} function gives the 3D points from the disparity map and the projection matrix.

\begin{lstlisting}[language=python, caption=Uncalibrated Rectification]
#rectification
_, H1, H2 = cv.stereoRectifyUncalibrated(
    np.float32(pts1), np.float32(pts2), f, imgSize=(w1, h1)
)

imgl_rectified = cv.warpPerspective(image_left, H1, (w1, h1))
imgr_rectified = cv.warpPerspective(image_right, H2, (w2, h2))

#Disparity Calculation
stereo = cv.StereoBM_create(numDisparities=16, blockSize=15)
disparity_BM = stereo.compute(imgl_rectified, imgr_rectified)

#Reprojection
image3d = cv.reprojectImageTo3D(disparity_map, Q, handleMissingValues=False)

\end{lstlisting}

%[opencv](https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html)
%[chavore]( https://github.com/bvnayak/CAHVOR_camera_model)

